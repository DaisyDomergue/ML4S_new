{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import shutil\n",
    "from logging import Logger\n",
    "import speechbrain as sb\n",
    "from pathlib import Path\n",
    "from speechbrain.utils.data_utils import get_all_files, download_file\n",
    "from speechbrain.dataio.dataio import read_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICANLE_AUDIO_DIR = \"./ICNALE_Spoken_Monologue_2.0_Audio/ICNALE_SM_ENS_N600\"\n",
    "ICANLE_TRANS_DIR = \"./ICNALE_Spoken_Monologue_2.0_Transcripts/Unmerged_classified/ICNALE_SM_ENS_XXX_NX00\"\n",
    "DATA_DIR = \"./data\"\n",
    "TRAIN_FILE = DATA_DIR+\"/train.json\"\n",
    "VALID_FILE = DATA_DIR+\"/valid.json\"\n",
    "TEST_FILE = DATA_DIR+\"/test.json\"\n",
    "AUDIO_EXT = [\".mp3\"]\n",
    "TRANS_EXT = [\".txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip(*filenames):\n",
    "    \"\"\"\n",
    "    Detects if the data preparation has been already done.\n",
    "    If the preparation has been done, we can skip it.\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        if True, the preparation phase can be skipped.\n",
    "        if False, it must be done.\n",
    "    \"\"\"\n",
    "    for filename in filenames:\n",
    "        if not os.path.isfile(filename):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcription(trans_list):\n",
    "    \"\"\"\n",
    "    Returns a dictionary with the transcription of each sentence in the dataset.\n",
    "    Arguments\n",
    "    ---------\n",
    "    trans_list : list of str\n",
    "        The list of transcription files.\n",
    "    \"\"\"\n",
    "    # Processing all the transcription files in the list\n",
    "    trans_dict = {}\n",
    "    for trans_file in trans_list:\n",
    "        # Reading the text file\n",
    "        with open(trans_file, encoding='utf-8-sig') as f:\n",
    "            text = f.read()\n",
    "            f.close()\n",
    "            name = Path(trans_file).stem\n",
    "            trans_dict[name] = text\n",
    "\n",
    "    return trans_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json(wav_list, trans_dict):\n",
    "    \"\"\"\n",
    "    Creates the json file given a list of mp3 files and their transcriptions.\n",
    "    Arguments\n",
    "    ---------\n",
    "    wav_list : list of str\n",
    "        The list of mp3 files.\n",
    "    trans_dict : dict\n",
    "        Dictionary of sentence ids and word transcriptions.\n",
    "    json_file : str\n",
    "        The path of the output json file\n",
    "    \"\"\"\n",
    "    # Processing all the wav files in the list\n",
    "    SAMPLERATE = 44100\n",
    "\n",
    "    json_dict = {}\n",
    "    for wav_file in wav_list:\n",
    "\n",
    "        # Reading the signal (to retrieve duration in seconds)\n",
    "        signal = read_audio(wav_file)\n",
    "        duration = signal.shape[0] / SAMPLERATE\n",
    "\n",
    "        # Manipulate path to get relative path and uttid\n",
    "        path_parts = wav_file.split(os.path.sep)\n",
    "        uttid, _ = os.path.splitext(path_parts[-1])\n",
    "        relative_path = os.path.join(\"{data_root}\", *path_parts[-5:])\n",
    "\n",
    "        # Create entry for this utterance\n",
    "        json_dict[uttid] = {\n",
    "            \"wav\": relative_path,\n",
    "            \"length\": duration,\n",
    "            \"words\": trans_dict[uttid],\n",
    "        }\n",
    "        key_list = list(json_dict)\n",
    "\n",
    "        random.shuffle(key_list)\n",
    "\n",
    "        data = {}\n",
    "\n",
    "        for key in key_list:\n",
    "                # print(key,json_dict[key])\n",
    "                data[key] = json_dict[key]\n",
    "    return data\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if skip(save_json_train, save_json_test):\n",
    "#         print(\"Preparation completed in previous run, skipping.\")\n",
    "#         return\n",
    "\n",
    "audio_files = get_all_files(ICANLE_AUDIO_DIR,match_and=AUDIO_EXT)\n",
    "trans_files = get_all_files(ICANLE_TRANS_DIR,match_and=TRANS_EXT)\n",
    "trans_dict = get_transcription(trans_files)\n",
    "data = create_json(audio_files,trans_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_store_data(data, training_json, valid_json, test_json):\n",
    "    end_idx_training = int(len(data)*(2/3))\n",
    "    end_idx_validation = int(len(data)*(2.5/3))\n",
    "    print(\"training,validation\",end_idx_training,end_idx_validation)\n",
    "    \n",
    "    print(end_idx_training)\n",
    "    training_dict = dict(list(data.items())[0:end_idx_training])\n",
    "    validation_dict = dict(list(data.items())[end_idx_training+1:end_idx_validation])\n",
    "    test_dict = dict(list(data.items())[end_idx_validation+1:-1])\n",
    "    print(\"length of training dict: \",len(training_dict))\n",
    "    print(\"length of valid dict: \",len(validation_dict))\n",
    "    print(\"length of test dict: \",len(test_dict))\n",
    "\n",
    "    # Writing the dictionary to the json file\n",
    "    with open(training_json, mode=\"w\") as json_f:\n",
    "        json.dump(training_dict, json_f, indent=2)\n",
    "    with open(valid_json, mode=\"w\") as json_f:\n",
    "        json.dump(validation_dict, json_f, indent=2)\n",
    "    with open(test_json, mode=\"w\") as json_f:\n",
    "        json.dump(test_dict, json_f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training,validation 400 500\n",
      "400\n",
      "length of training dict:  400\n",
      "length of valid dict:  99\n",
      "length of test dict:  98\n"
     ]
    }
   ],
   "source": [
    "split_and_store_data(data,TRAIN_FILE,VALID_FILE,TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.5 ('rtx_3060')' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'conda install -n rtx_3060 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "torch.tensor([1.0, 2.0])\n",
    "torch.tensor([1.0, 2.0]).cuda()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
