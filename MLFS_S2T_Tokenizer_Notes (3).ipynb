{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a263bda",
   "metadata": {},
   "source": [
    "<h1> Tokenizer </h1>\n",
    "\n",
    "Notes from:\n",
    "\n",
    "https://colab.research.google.com/drive/1aFgzrUv3udM_gNJNUoLaHIm78QHtxdIz?usp=sharing#scrollTo=tA4HMrnFJ33e\n",
    "\n",
    "SentencePiece tokenizer is included in Speechbrain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "258e27b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sentencepiece as spm\n",
    "from speechbrain.tokenizers.SentencePiece import SentencePiece\n",
    "from speechbrain.utils.data_utils import get_all_files, download_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf4437f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"/mnt/c/Users/Gaia/Documents/Schoolwork/ML4S/ICNALE_SM_2.0_A\"\n",
    "transcript_dir = \"./ICNALE_Spoken_Monologue_2.0_Transcripts/Unmerged_classified/ICNALE_SM_ENS_XXX_NX00\"\n",
    "os.chdir(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09da8024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick vocab and token count across the corpus \n",
    "\n",
    "trans_files = get_all_files(transcript_dir, match_and='.txt')\n",
    "\n",
    "def build_vocab(trans_files):\n",
    "    vocab = {}\n",
    "    token_count = 0\n",
    "    index = 0\n",
    "    for file in trans_files:  \n",
    "        with open(file) as f:\n",
    "            text = f.read()\n",
    "            text = re.sub('\\ufeff', '', text)\n",
    "            text = re.sub('\\n', ' ', text)\n",
    "            tokens = [a.strip('.,- ').lower() for a in text.split(' ') if a!='']\n",
    "            token_count += len(tokens)\n",
    "            tokens = set(tokens)\n",
    "            for token in tokens:\n",
    "                if token not in vocab.values():\n",
    "                    vocab[index] = token\n",
    "                    index += 1\n",
    "    return vocab, token_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1372dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3781 92431\n"
     ]
    }
   ],
   "source": [
    "vocab, token_count = build_vocab(trans_files)\n",
    "print(len(vocab), token_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85199f5e",
   "metadata": {},
   "source": [
    "For the tokenizer, we want something that can generalize well to words the model has not seen, so that the model can (in theory) perform well on the test set. \n",
    "\n",
    "We should also think about the probability distribution across the tokens: with a vocabulary of 7k, I have a feeling that the model will revert to the most frequent words automatically if we just take the probability dist across all possible tokens (not to mention, tokens not trained on will get zero prior probability and will not be output during testing). \n",
    "\n",
    "This is additionally a problem because learners have very sparse vocabularies generally, so a few words ('I', 'because', 'um', 'and') will dominate the distribution. We may even have to take this into account and use some kind of smoothing (or whatever it's called) somewhere in the model to boost low-frequency tokens during prediction.\n",
    "\n",
    "Below are my experiments with the SentencePiece tokenizer, which is included in Speechbrain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06a4715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32c783eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁I', '▁think', '▁because', '▁you', '▁make', '▁me'] \n",
      "\n",
      " [25, 87, 133, 43, 426, 188] \n",
      "\n",
      " ['▁wor', 'd', 'l', 'able', '▁j', 'ib', 'b', 'er', 'is', 'h', '▁co', 'j', 'ec', 'ture']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=./data/training.txt --model_prefix=tokenizers/676_bpe --model_type=bpe --bos_id=-1 --eos_id=-1 --pad_id=-1 --unk_id=0 --max_sentencepiece_length=10 --character_coverage=1.0 --add_dummy_prefix=True --vocab_size=676\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ./data/training.txt\n",
      "  input_format: \n",
      "  model_prefix: tokenizers/676_bpe\n",
      "  model_type: BPE\n",
      "  vocab_size: 676\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 10\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: -1\n",
      "  eos_id: -1\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: ./data/training.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 600 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=498562\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=84\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 600 sentences.\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 600\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 5723\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=15268 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3379 size=20 all=1254 active=1170 piece=nd\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2000 size=40 all=1599 active=1515 piece=▁smok\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1403 size=60 all=1888 active=1804 piece=▁is\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=990 size=80 all=2120 active=2036 piece=al\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=807 size=100 all=2367 active=2283 piece=▁go\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=792 min_freq=16\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=652 size=120 all=2630 active=1259 piece=ause\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=537 size=140 all=2901 active=1530 piece=ers\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=460 size=160 all=3103 active=1732 piece=▁ban\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=387 size=180 all=3284 active=1913 piece=▁an\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=331 size=200 all=3427 active=2056 piece=▁ne\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=328 min_freq=19\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=293 size=220 all=3622 active=1190 piece=▁this\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=249 size=240 all=3796 active=1364 piece=eve\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=221 size=260 all=3945 active=1513 piece=▁man\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=204 size=280 all=4103 active=1671 piece=▁while\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=184 size=300 all=4218 active=1786 piece=ea\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=184 min_freq=18\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=171 size=320 all=4321 active=1088 piece='\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=157 size=340 all=4401 active=1168 piece=▁pr\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=142 size=360 all=4473 active=1240 piece=wn\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=126 size=380 all=4557 active=1324 piece=sh\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=119 size=400 all=4680 active=1447 piece=▁cl\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=119 min_freq=16\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=112 size=420 all=4805 active=1118 piece=age\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=106 size=440 all=4922 active=1235 piece=▁They\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=97 size=460 all=5010 active=1323 piece=specially\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=91 size=480 all=5071 active=1384 piece=▁take\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=85 size=500 all=5174 active=1487 piece=▁pare\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=85 min_freq=14\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=80 size=520 all=5203 active=1028 piece=▁under\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=76 size=540 all=5288 active=1113 piece=lem\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=71 size=560 all=5333 active=1158 piece=icul\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=67 size=580 all=5417 active=1242 piece=▁gives\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: tokenizers/676_bpe.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: tokenizers/676_bpe.vocab\n"
     ]
    }
   ],
   "source": [
    "#creates, trains, and saves tokenizer\n",
    "SentencePiece(\n",
    "    model_dir = 'tokenizers',\n",
    "    vocab_size = 26**2, #experiment with values here\n",
    "    annotation_train = './data/training.json', #.json train manifest\n",
    "    annotation_read = 'words', #key from .json with val text string\n",
    "    model_type = 'bpe',\n",
    "    annotation_format = 'json'\n",
    ")\n",
    "\n",
    "\n",
    "sp.load('tokenizers/676_bpe.model') #path to tokenizer model\n",
    "\n",
    "#test on common words and pseudowords, and\n",
    "# demonstrate ID encoding (for use with model)\n",
    "\n",
    "#with bpe vocab size = 676\n",
    "print(sp.encode_as_pieces('I think because you make me'), '\\n\\n', \n",
    "      sp.encode_as_ids('I think because you make me'), \n",
    "      '\\n\\n', sp.encode_as_pieces('wordlable jibberish cojecture'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "848efe4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁I', '▁think', '▁because', '▁you', '▁make', '▁me'] \n",
      "\n",
      " \n",
      "\n",
      " ['▁wor', 'd', 'l', 'able', '▁j', 'ib', 'ber', 'ish', '▁co', 'j', 'ec', 'ture']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=./data/training.txt --model_prefix=tokenizers/2600_bpe --model_type=bpe --bos_id=-1 --eos_id=-1 --pad_id=-1 --unk_id=0 --max_sentencepiece_length=10 --character_coverage=1.0 --add_dummy_prefix=True --vocab_size=2600\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ./data/training.txt\n",
      "  input_format: \n",
      "  model_prefix: tokenizers/2600_bpe\n",
      "  model_type: BPE\n",
      "  vocab_size: 2600\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 10\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: -1\n",
      "  eos_id: -1\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: ./data/training.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 600 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=498562\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=84\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 600 sentences.\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 600\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 5723\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=15268 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3379 size=20 all=1254 active=1170 piece=nd\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2000 size=40 all=1599 active=1515 piece=▁smok\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1403 size=60 all=1888 active=1804 piece=▁is\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=990 size=80 all=2120 active=2036 piece=al\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=807 size=100 all=2367 active=2283 piece=▁go\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=792 min_freq=16\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=652 size=120 all=2630 active=1259 piece=ause\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=537 size=140 all=2901 active=1530 piece=ers\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=460 size=160 all=3103 active=1732 piece=▁ban\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=387 size=180 all=3284 active=1913 piece=▁an\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=331 size=200 all=3427 active=2056 piece=▁ne\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=328 min_freq=19\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=293 size=220 all=3622 active=1190 piece=▁this\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=249 size=240 all=3796 active=1364 piece=eve\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=221 size=260 all=3945 active=1513 piece=▁man\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=204 size=280 all=4103 active=1671 piece=▁while\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=184 size=300 all=4218 active=1786 piece=ea\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=184 min_freq=18\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=171 size=320 all=4321 active=1088 piece='\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=157 size=340 all=4401 active=1168 piece=▁pr\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=142 size=360 all=4473 active=1240 piece=wn\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=126 size=380 all=4557 active=1324 piece=sh\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=119 size=400 all=4680 active=1447 piece=▁cl\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=119 min_freq=16\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=112 size=420 all=4805 active=1118 piece=age\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=106 size=440 all=4922 active=1235 piece=▁They\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=97 size=460 all=5010 active=1323 piece=specially\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=91 size=480 all=5071 active=1384 piece=▁take\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=85 size=500 all=5174 active=1487 piece=▁pare\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=85 min_freq=14\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=80 size=520 all=5203 active=1028 piece=▁under\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=76 size=540 all=5288 active=1113 piece=lem\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=71 size=560 all=5333 active=1158 piece=icul\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=67 size=580 all=5417 active=1242 piece=▁gives\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=65 size=600 all=5525 active=1350 piece=▁full\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=65 min_freq=12\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=62 size=620 all=5567 active=1041 piece=ol\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=60 size=640 all=5637 active=1111 piece=▁lo\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=57 size=660 all=5710 active=1184 piece=▁--\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=55 size=680 all=5734 active=1208 piece=▁state\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=51 size=700 all=5800 active=1274 piece=▁course\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=51 min_freq=11\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=49 size=720 all=5872 active=1072 piece=▁separ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=47 size=740 all=5921 active=1121 piece=▁hab\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=45 size=760 all=5957 active=1157 piece=▁example\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=42 size=780 all=5997 active=1197 piece=▁inside\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=40 size=800 all=6032 active=1232 piece=▁dist\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=40 min_freq=9\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=38 size=820 all=6056 active=1020 piece=▁academ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=36 size=840 all=6085 active=1049 piece=▁str\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=35 size=860 all=6093 active=1057 piece=▁financial\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=33 size=880 all=6125 active=1089 piece=▁either\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=32 size=900 all=6148 active=1112 piece=atever\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=32 min_freq=8\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=31 size=920 all=6176 active=1028 piece=▁taste\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=30 size=940 all=6209 active=1061 piece=▁living\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=29 size=960 all=6246 active=1098 piece=▁provid\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=28 size=980 all=6295 active=1147 piece=▁social\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=27 size=1000 all=6348 active=1200 piece=▁become\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=27 min_freq=8\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=26 size=1020 all=6401 active=1053 piece=▁sub\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=25 size=1040 all=6442 active=1094 piece=ered\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=24 size=1060 all=6474 active=1126 piece=ween\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=23 size=1080 all=6476 active=1128 piece=day\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=23 size=1100 all=6505 active=1157 piece=▁countries\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=22 min_freq=7\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=22 size=1120 all=6544 active=1040 piece=▁pretty\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=21 size=1140 all=6591 active=1087 piece=▁leave\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=20 size=1160 all=6602 active=1098 piece=▁inf\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=20 size=1180 all=6616 active=1112 piece=▁classes\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19 size=1200 all=6662 active=1158 piece=▁bar\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=19 min_freq=6\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19 size=1220 all=6678 active=1016 piece=▁smelling\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=18 size=1240 all=6717 active=1055 piece=▁char\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17 size=1260 all=6714 active=1052 piece=av\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17 size=1280 all=6760 active=1098 piece=▁concer\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16 size=1300 all=6791 active=1129 piece=▁fur\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=16 min_freq=6\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16 size=1320 all=6794 active=1003 piece=▁appreci\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15 size=1340 all=6800 active=1009 piece=epend\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15 size=1360 all=6812 active=1021 piece=▁schedule\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14 size=1380 all=6851 active=1060 piece=▁must\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14 size=1400 all=6848 active=1057 piece=▁affecting\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=13 min_freq=5\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13 size=1420 all=6897 active=1050 piece=▁equ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13 size=1440 all=6908 active=1061 piece=▁damage\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12 size=1460 all=6907 active=1060 piece=coh\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12 size=1480 all=6946 active=1099 piece=▁thr\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12 size=1500 all=6966 active=1119 piece=▁begin\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=12 min_freq=5\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12 size=1520 all=6953 active=986 piece=▁damaging\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11 size=1540 all=6970 active=1003 piece=▁ple\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11 size=1560 all=6981 active=1014 piece=▁third\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11 size=1580 all=6971 active=1004 piece=▁helpful\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10 size=1600 all=6992 active=1025 piece=nce\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=10 min_freq=4\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10 size=1620 all=7039 active=1045 piece=esses\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10 size=1640 all=7049 active=1055 piece=▁fully\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10 size=1660 all=7044 active=1050 piece=▁smoked\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10 size=1680 all=7035 active=1041 piece=▁separated\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9 size=1700 all=7079 active=1085 piece=ized\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=9 min_freq=4\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9 size=1720 all=7111 active=1029 piece=stroy\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9 size=1740 all=7112 active=1030 piece=▁multi\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9 size=1760 all=7104 active=1022 piece=▁careers\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9 size=1780 all=7088 active=1006 piece=▁talented\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=1800 all=7110 active=1028 piece=aled\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=8 min_freq=4\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=1820 all=7137 active=1027 piece=onest\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=1840 all=7138 active=1028 piece=▁sign\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=1860 all=7131 active=1021 piece=iratory\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=1880 all=7118 active=1008 piece=▁density\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=1900 all=7099 active=989 piece=▁otherwise\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=8 min_freq=3\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=1920 all=7139 active=1041 piece=bing\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=1940 all=7170 active=1072 piece=▁lim\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=1960 all=7186 active=1088 piece=▁hair\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=1980 all=7188 active=1090 piece=▁kills\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=2000 all=7174 active=1076 piece=▁caused\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=7 min_freq=3\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=2020 all=7168 active=995 piece=▁Further\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=2040 all=7151 active=978 piece=▁remember\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=2060 all=7161 active=988 piece=hib\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=2080 all=7187 active=1014 piece=ilst\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=2100 all=7201 active=1028 piece=▁suc\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=6 min_freq=3\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=2120 all=7208 active=1006 piece=▁grow\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=2140 all=7212 active=1010 piece=▁carry\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=2160 all=7212 active=1010 piece=▁accept\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=2180 all=7198 active=996 piece=entially\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=2200 all=7180 active=978 piece=▁special\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=6 min_freq=3\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=2220 all=7160 active=981 piece=▁dependent\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=2240 all=7184 active=1005 piece=ior\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=2260 all=7207 active=1028 piece=iced\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=2280 all=7231 active=1052 piece=▁sim\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=2300 all=7241 active=1062 piece=▁isol\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=5 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=2320 all=7242 active=999 piece=▁built\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=2340 all=7236 active=993 piece=▁approp\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=2360 all=7220 active=977 piece=▁throat\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=2380 all=7203 active=960 piece=▁success\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=2400 all=7184 active=941 piece=▁clientele\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=5 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=2420 all=7194 active=1011 piece=ata\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=2440 all=7233 active=1050 piece=uts\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=2460 all=7246 active=1063 piece=ions\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=2480 all=7265 active=1082 piece=▁gas\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=2500 all=7286 active=1103 piece=ndred\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=4 min_freq=2\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: tokenizers/2600_bpe.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: tokenizers/2600_bpe.vocab\n"
     ]
    }
   ],
   "source": [
    "#bpe vocab size = 2600\n",
    "\n",
    "SentencePiece(\n",
    "    model_dir = 'tokenizers',\n",
    "    vocab_size = 26*100, #experiment with values here\n",
    "    annotation_train = './data/training.json', #.json train manifest\n",
    "    annotation_read = 'words', #key from .json with val text string\n",
    "    model_type = 'bpe',\n",
    "    annotation_format = 'json'\n",
    ")\n",
    "\n",
    "sp.load('tokenizers/2600_bpe.model')\n",
    "\n",
    "print(sp.encode_as_pieces('I think because you make me'), '\\n\\n',  \n",
    "      '\\n\\n', sp.encode_as_pieces('wordlable jibberish cojecture'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2e904a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁I', '▁think', '▁because', '▁you', '▁make', '▁me'] \n",
      "\n",
      " \n",
      "\n",
      " ['▁w', 'or', 'd', 'l', 'able', '▁', 'j', 'i', 'b', 'b', 'er', 'i', 's', 'h', '▁co', 'j', 'e', 'c', 't', 'u', 're']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=./data/training.txt --model_prefix=tokenizers/676_unigram --model_type=unigram --bos_id=-1 --eos_id=-1 --pad_id=-1 --unk_id=0 --max_sentencepiece_length=10 --character_coverage=1.0 --add_dummy_prefix=True --vocab_size=676\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ./data/training.txt\n",
      "  input_format: \n",
      "  model_prefix: tokenizers/676_unigram\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 676\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 10\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: -1\n",
      "  eos_id: -1\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: ./data/training.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 600 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=498562\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=84\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 600 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 10521 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 600\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 5723\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 5723 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=3947 obj=9.39059 num_tokens=11311 num_tokens/piece=2.86572\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=3146 obj=7.32325 num_tokens=11379 num_tokens/piece=3.61697\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=2358 obj=7.35096 num_tokens=12315 num_tokens/piece=5.22265\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=2356 obj=7.32332 num_tokens=12355 num_tokens/piece=5.24406\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=1767 obj=7.49752 num_tokens=14159 num_tokens/piece=8.01302\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=1766 obj=7.46112 num_tokens=14159 num_tokens/piece=8.01755\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=1324 obj=7.71617 num_tokens=16465 num_tokens/piece=12.4358\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=1324 obj=7.67166 num_tokens=16464 num_tokens/piece=12.435\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=993 obj=7.99745 num_tokens=18997 num_tokens/piece=19.1309\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=993 obj=7.94834 num_tokens=18998 num_tokens/piece=19.1319\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=744 obj=8.3584 num_tokens=21475 num_tokens/piece=28.8642\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=744 obj=8.28954 num_tokens=21475 num_tokens/piece=28.8642\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=743 obj=8.29036 num_tokens=21481 num_tokens/piece=28.9112\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=743 obj=8.29009 num_tokens=21481 num_tokens/piece=28.9112\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: tokenizers/676_unigram.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: tokenizers/676_unigram.vocab\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#unigram vocab size = 676\n",
    "\n",
    "SentencePiece(\n",
    "    model_dir = 'tokenizers',\n",
    "    vocab_size = 26**2, #experiment with values here\n",
    "    annotation_train = './data/training.json', #.json train manifest\n",
    "    annotation_read = 'words', #key from .json with val text string\n",
    "    model_type = 'unigram',\n",
    "    annotation_format = 'json'\n",
    ")\n",
    "\n",
    "sp.load('tokenizers/676_unigram.model')\n",
    "\n",
    "print(sp.encode_as_pieces('I think because you make me'), '\\n\\n',  \n",
    "      '\\n\\n', sp.encode_as_pieces('wordlable jibberish cojecture'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1cd7c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁I', '▁think', '▁because', '▁you', '▁make', '▁me'] \n",
      "\n",
      " ['▁wor', 'd', 'l', 'able', '▁', 'j', 'i', 'b', 'b', 'er', 'ish', '▁co', 'j', 'e', 'c', 't', 'ure']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=./data/training.txt --model_prefix=tokenizers/2600_unigram --model_type=unigram --bos_id=-1 --eos_id=-1 --pad_id=-1 --unk_id=0 --max_sentencepiece_length=10 --character_coverage=1.0 --add_dummy_prefix=True --vocab_size=2600\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ./data/training.txt\n",
      "  input_format: \n",
      "  model_prefix: tokenizers/2600_unigram\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 2600\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 10\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: -1\n",
      "  eos_id: -1\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: ./data/training.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 600 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=498562\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=84\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 600 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 10521 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 600\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 5723\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 5723 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=3947 obj=9.39059 num_tokens=11311 num_tokens/piece=2.86572\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=3146 obj=7.32325 num_tokens=11379 num_tokens/piece=3.61697\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=2853 obj=7.30008 num_tokens=11566 num_tokens/piece=4.05398\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=2843 obj=7.28828 num_tokens=11611 num_tokens/piece=4.08407\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: tokenizers/2600_unigram.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: tokenizers/2600_unigram.vocab\n"
     ]
    }
   ],
   "source": [
    "SentencePiece(\n",
    "    model_dir = 'tokenizers',\n",
    "    vocab_size = 26*100, #What would be a good value here?\n",
    "    annotation_train = './data/training.json', #.json train manifest\n",
    "    annotation_read = 'words', #key with text string\n",
    "    model_type = 'unigram',\n",
    "    annotation_format = 'json'\n",
    ")\n",
    "\n",
    "#unigram with 2600 vocab size \n",
    "sp.load('tokenizers/2600_unigram.model')\n",
    "print(sp.encode_as_pieces('I think because you make me'), '\\n\\n',\n",
    "sp.encode_as_pieces('wordlable jibberish cojecture'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52697c40",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁I', '▁think', '▁because', '▁you', '▁make', '▁me'] \n",
      "\n",
      " ['▁word', 'l', 'able', '▁j', 'i', 'b', 'be', 'r', 'ish', '▁co', 'j', 'e', 'c', 't', 'ure']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=./data/training.txt --model_prefix=tokenizers/3174_unigram --model_type=unigram --bos_id=-1 --eos_id=-1 --pad_id=-1 --unk_id=0 --max_sentencepiece_length=10 --character_coverage=1.0 --add_dummy_prefix=True --vocab_size=3174\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ./data/training.txt\n",
      "  input_format: \n",
      "  model_prefix: tokenizers/3174_unigram\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 3174\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 10\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: -1\n",
      "  eos_id: -1\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: ./data/training.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 600 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=498562\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=84\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 600 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 10521 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 600\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 5723\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 5723 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=3947 obj=9.39059 num_tokens=11311 num_tokens/piece=2.86572\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=3146 obj=7.32325 num_tokens=11379 num_tokens/piece=3.61697\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: tokenizers/3174_unigram.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: tokenizers/3174_unigram.vocab\n"
     ]
    }
   ],
   "source": [
    "SentencePiece(\n",
    "    model_dir = 'tokenizers',\n",
    "    vocab_size = 3174, #This is 'max' value \n",
    "    annotation_train = './data/training.json', #.json train manifest\n",
    "    annotation_read = 'words', #key with text string\n",
    "    model_type = 'unigram',\n",
    "    annotation_format = 'json'\n",
    ")\n",
    "\n",
    "#unigram with vocab size 3174\n",
    "sp.load('tokenizers/3174_unigram.model')\n",
    "print(sp.encode_as_pieces('I think because you make me'), '\\n\\n',\n",
    "sp.encode_as_pieces('wordlable jibberish cojecture'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af9b2565",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁I', '▁think', '▁because', '▁you', '▁make', '▁me'] \n",
      "\n",
      " ['▁wor', 'd', 'l', 'able', '▁j', 'ib', 'ber', 'ish', '▁co', 'j', 'ec', 'ture']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=./data/training.txt --model_prefix=tokenizers/3174_bpe --model_type=bpe --bos_id=-1 --eos_id=-1 --pad_id=-1 --unk_id=0 --max_sentencepiece_length=10 --character_coverage=1.0 --add_dummy_prefix=True --vocab_size=3174\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ./data/training.txt\n",
      "  input_format: \n",
      "  model_prefix: tokenizers/3174_bpe\n",
      "  model_type: BPE\n",
      "  vocab_size: 3174\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 10\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: -1\n",
      "  eos_id: -1\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: ./data/training.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 600 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=498562\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=84\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 600 sentences.\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 600\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 5723\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=15268 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3379 size=20 all=1254 active=1170 piece=nd\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2000 size=40 all=1599 active=1515 piece=▁smok\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1403 size=60 all=1888 active=1804 piece=▁is\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=990 size=80 all=2120 active=2036 piece=al\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=807 size=100 all=2367 active=2283 piece=▁go\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=792 min_freq=16\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=652 size=120 all=2630 active=1259 piece=ause\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=537 size=140 all=2901 active=1530 piece=ers\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=460 size=160 all=3103 active=1732 piece=▁ban\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=387 size=180 all=3284 active=1913 piece=▁an\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=331 size=200 all=3427 active=2056 piece=▁ne\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=328 min_freq=19\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=293 size=220 all=3622 active=1190 piece=▁this\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=249 size=240 all=3796 active=1364 piece=eve\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=221 size=260 all=3945 active=1513 piece=▁man\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=204 size=280 all=4103 active=1671 piece=▁while\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=184 size=300 all=4218 active=1786 piece=ea\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=184 min_freq=18\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=171 size=320 all=4321 active=1088 piece='\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=157 size=340 all=4401 active=1168 piece=▁pr\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=142 size=360 all=4473 active=1240 piece=wn\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=126 size=380 all=4557 active=1324 piece=sh\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=119 size=400 all=4680 active=1447 piece=▁cl\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=119 min_freq=16\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=112 size=420 all=4805 active=1118 piece=age\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=106 size=440 all=4922 active=1235 piece=▁They\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=97 size=460 all=5010 active=1323 piece=specially\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=91 size=480 all=5071 active=1384 piece=▁take\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=85 size=500 all=5174 active=1487 piece=▁pare\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=85 min_freq=14\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=80 size=520 all=5203 active=1028 piece=▁under\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=76 size=540 all=5288 active=1113 piece=lem\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=71 size=560 all=5333 active=1158 piece=icul\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=67 size=580 all=5417 active=1242 piece=▁gives\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=65 size=600 all=5525 active=1350 piece=▁full\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=65 min_freq=12\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=62 size=620 all=5567 active=1041 piece=ol\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=60 size=640 all=5637 active=1111 piece=▁lo\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=57 size=660 all=5710 active=1184 piece=▁--\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=55 size=680 all=5734 active=1208 piece=▁state\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=51 size=700 all=5800 active=1274 piece=▁course\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=51 min_freq=11\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=49 size=720 all=5872 active=1072 piece=▁separ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=47 size=740 all=5921 active=1121 piece=▁hab\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=45 size=760 all=5957 active=1157 piece=▁example\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=42 size=780 all=5997 active=1197 piece=▁inside\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=40 size=800 all=6032 active=1232 piece=▁dist\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=40 min_freq=9\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=38 size=820 all=6056 active=1020 piece=▁academ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=36 size=840 all=6085 active=1049 piece=▁str\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=35 size=860 all=6093 active=1057 piece=▁financial\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=33 size=880 all=6125 active=1089 piece=▁either\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=32 size=900 all=6148 active=1112 piece=atever\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=32 min_freq=8\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=31 size=920 all=6176 active=1028 piece=▁taste\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=30 size=940 all=6209 active=1061 piece=▁living\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=29 size=960 all=6246 active=1098 piece=▁provid\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=28 size=980 all=6295 active=1147 piece=▁social\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=27 size=1000 all=6348 active=1200 piece=▁become\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=27 min_freq=8\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=26 size=1020 all=6401 active=1053 piece=▁sub\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=25 size=1040 all=6442 active=1094 piece=ered\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=24 size=1060 all=6474 active=1126 piece=ween\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=23 size=1080 all=6476 active=1128 piece=day\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=23 size=1100 all=6505 active=1157 piece=▁countries\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=22 min_freq=7\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=22 size=1120 all=6544 active=1040 piece=▁pretty\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=21 size=1140 all=6591 active=1087 piece=▁leave\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=20 size=1160 all=6602 active=1098 piece=▁inf\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=20 size=1180 all=6616 active=1112 piece=▁classes\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19 size=1200 all=6662 active=1158 piece=▁bar\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=19 min_freq=6\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19 size=1220 all=6678 active=1016 piece=▁smelling\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=18 size=1240 all=6717 active=1055 piece=▁char\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17 size=1260 all=6714 active=1052 piece=av\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17 size=1280 all=6760 active=1098 piece=▁concer\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16 size=1300 all=6791 active=1129 piece=▁fur\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=16 min_freq=6\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16 size=1320 all=6794 active=1003 piece=▁appreci\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15 size=1340 all=6800 active=1009 piece=epend\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15 size=1360 all=6812 active=1021 piece=▁schedule\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14 size=1380 all=6851 active=1060 piece=▁must\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14 size=1400 all=6848 active=1057 piece=▁affecting\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=13 min_freq=5\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13 size=1420 all=6897 active=1050 piece=▁equ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13 size=1440 all=6908 active=1061 piece=▁damage\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12 size=1460 all=6907 active=1060 piece=coh\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12 size=1480 all=6946 active=1099 piece=▁thr\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12 size=1500 all=6966 active=1119 piece=▁begin\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=12 min_freq=5\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12 size=1520 all=6953 active=986 piece=▁damaging\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11 size=1540 all=6970 active=1003 piece=▁ple\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11 size=1560 all=6981 active=1014 piece=▁third\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11 size=1580 all=6971 active=1004 piece=▁helpful\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10 size=1600 all=6992 active=1025 piece=nce\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=10 min_freq=4\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10 size=1620 all=7039 active=1045 piece=esses\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10 size=1640 all=7049 active=1055 piece=▁fully\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10 size=1660 all=7044 active=1050 piece=▁smoked\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10 size=1680 all=7035 active=1041 piece=▁separated\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9 size=1700 all=7079 active=1085 piece=ized\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=9 min_freq=4\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9 size=1720 all=7111 active=1029 piece=stroy\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9 size=1740 all=7112 active=1030 piece=▁multi\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9 size=1760 all=7104 active=1022 piece=▁careers\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9 size=1780 all=7088 active=1006 piece=▁talented\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=1800 all=7110 active=1028 piece=aled\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=8 min_freq=4\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=1820 all=7137 active=1027 piece=onest\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=1840 all=7138 active=1028 piece=▁sign\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=1860 all=7131 active=1021 piece=iratory\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=1880 all=7118 active=1008 piece=▁density\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=1900 all=7099 active=989 piece=▁otherwise\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=8 min_freq=3\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=1920 all=7139 active=1041 piece=bing\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=1940 all=7170 active=1072 piece=▁lim\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=1960 all=7186 active=1088 piece=▁hair\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=1980 all=7188 active=1090 piece=▁kills\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=2000 all=7174 active=1076 piece=▁caused\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=7 min_freq=3\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=2020 all=7168 active=995 piece=▁Further\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=2040 all=7151 active=978 piece=▁remember\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=2060 all=7161 active=988 piece=hib\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=2080 all=7187 active=1014 piece=ilst\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=2100 all=7201 active=1028 piece=▁suc\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=6 min_freq=3\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=2120 all=7208 active=1006 piece=▁grow\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=2140 all=7212 active=1010 piece=▁carry\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=2160 all=7212 active=1010 piece=▁accept\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=2180 all=7198 active=996 piece=entially\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=2200 all=7180 active=978 piece=▁special\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=6 min_freq=3\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=2220 all=7160 active=981 piece=▁dependent\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=2240 all=7184 active=1005 piece=ior\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=2260 all=7207 active=1028 piece=iced\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=2280 all=7231 active=1052 piece=▁sim\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=2300 all=7241 active=1062 piece=▁isol\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=5 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=2320 all=7242 active=999 piece=▁built\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=2340 all=7236 active=993 piece=▁approp\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=2360 all=7220 active=977 piece=▁throat\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=2380 all=7203 active=960 piece=▁success\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=2400 all=7184 active=941 piece=▁clientele\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=5 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=2420 all=7194 active=1011 piece=ata\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=2440 all=7233 active=1050 piece=uts\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=2460 all=7246 active=1063 piece=ions\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=2480 all=7265 active=1082 piece=▁gas\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=2500 all=7286 active=1103 piece=ndred\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=4 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=2520 all=7291 active=1004 piece=▁gone\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=2540 all=7284 active=997 piece=mented\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=2560 all=7278 active=991 piece=▁close\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=2580 all=7268 active=981 piece=▁share\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=2600 all=7260 active=973 piece=▁write\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=4 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=2620 all=7248 active=989 piece=▁listen\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=2640 all=7237 active=978 piece=▁Univers\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=2660 all=7222 active=963 piece=▁reports\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=2680 all=7203 active=944 piece=▁horrible\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=2700 all=7186 active=927 piece=▁vicinity\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=4 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=2720 all=7166 active=981 piece=▁qualities\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=2740 all=7192 active=1007 piece=arr\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=2760 all=7229 active=1044 piece=rew\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=2780 all=7237 active=1052 piece=gest\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=2800 all=7257 active=1072 piece=▁Him\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=2820 all=7266 active=1010 piece=▁sol\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=2840 all=7279 active=1023 piece=uling\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=2860 all=7274 active=1018 piece=▁dine\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=2880 all=7265 active=1009 piece=▁laws\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=2900 all=7255 active=999 piece=▁wind\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=2920 all=7257 active=1001 piece=▁above\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=2940 all=7246 active=990 piece=▁hobby\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=2960 all=7240 active=984 piece=▁stuck\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=2980 all=7229 active=973 piece=▁Unless\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=3000 all=7218 active=962 piece=▁fourth\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=3 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=3020 all=7205 active=988 piece=▁seeing\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=3040 all=7185 active=968 piece=▁entails\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=3060 all=7167 active=950 piece=▁portion\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3 size=3080 all=7148 active=931 piece=▁contamin\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: tokenizers/3174_bpe.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: tokenizers/3174_bpe.vocab\n"
     ]
    }
   ],
   "source": [
    "SentencePiece(\n",
    "    model_dir = 'tokenizers',\n",
    "    vocab_size = 3174, #This is 'max' value \n",
    "    annotation_train = './data/training.json', #.json train manifest\n",
    "    annotation_read = 'words', #key with text string\n",
    "    model_type = 'bpe',\n",
    "    annotation_format = 'json'\n",
    ")\n",
    "\n",
    "#unigram with vocab size 3174\n",
    "sp.load('tokenizers/3174_bpe.model')\n",
    "print(sp.encode_as_pieces('I think because you make me'), '\\n\\n',\n",
    "sp.encode_as_pieces('wordlable jibberish cojecture'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37bc854",
   "metadata": {},
   "source": [
    "The max vocabulary models 3174 lead to the best results but large vocabulary may bog down the training process. So far, I am recommending either the unigram or bpe with 2600 vocabulary. They capture both some morphological features (affixes) as well as the most frequent whole words, while keeping the vocabulary size (kinda) low. \n",
    "\n",
    "This might help the model make connections between phonemes and segments/syllables, rather than just word-to-word.\n",
    "\n",
    "\n",
    "I am not sure how this affects the search space during decoding - there is probably a tradeoff, because these sub-word token approaches yield longer sequences but have fewer (softmax?) probabilities to assign per sequence position. \n",
    "\n",
    "Also, my numbers for vocabulary size are just guesses, they are not really informed. If it is found that 2600 is too big, we can trim it down, maybe 1200 or 1600 would be good choices. If we have time, it might be fun to test different tokenization approaches in our pipeline and the effects that they have on output and computational time. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
